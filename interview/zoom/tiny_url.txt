requirements:
1. long url -> short url 
2. TTL = 6month not visited

3. qps : read = 20000 qps
write = 1000 qps

1000 qps * 60*60* 24 * 30*6

15G * 50B -> 1000G 存储内容

6 机器
300G 量 

number % 6 = [0,5] 

一致性哈希：
[4-5] -> machine:node5[0-4.5], node6:[4.5-5]


APIs:
string create_short_url(api_key, long_url,timestamp)
string get_short_url(api_key, short_url)

client -> short_url -> 301 with long url -> visit long url.


number = hash(long_url)
					  string to(number);
return get_short_string(string)

map[short] = long
visite short->long
client->APP server -> DB proxy: DB(short url->long)


DBproxy:  代理DB操作，并进行分片路由
read: 
write:

client ->LB -> APPServer -> LB -> DBProxy -> DB 
 						 -> Cache -> DB 

客户端 -> TinyURL 服务
      -> Redis 缓存（命中直接返回）
      -> 未命中 -> 数据库查找 -> 回写缓存
读瓶颈： 使用redis cache缓存 + bloom filter  + CDN 
写瓶颈： 分布式ID生成 + 批量段号分配

DB瓶颈： 读写分离 + 消息队列异步写

存储瓶颈： 数据分片 分库/分表
架构层面： 拆分服务 + 异步写入 + 自动扩容


自动清理冷数据URL: > 6month
client -> short
url(msg, timestamp) -> msg_ queue -> consume->table2

table1 : short -> long read
table2 : short -> TTL, 异步来写
clean : 6month->异步来做
read table2 and delete table1